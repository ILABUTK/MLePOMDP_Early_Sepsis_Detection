{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import\r\n",
    "import pickle\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# data diectory, modify before use\r\n",
    "data_dir = \"scripts/1_preprocessing\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# for each horizon\r\n",
    "for horizon in [1, 6, 12]:\r\n",
    "    # load patient ID\r\n",
    "    separate_id = pickle.load(open(\r\n",
    "        data_dir + \"/processed_data/ids/{}h_ID.pickle\".format(horizon), \"rb\"\r\n",
    "    ))\r\n",
    "    sepsis_id, nonsep_id = separate_id['sepsis'], separate_id['nonsep']\r\n",
    "    # combine id\r\n",
    "    all_id = sepsis_id + nonsep_id\r\n",
    "    # time stamps\r\n",
    "    time_stamp = pd.DataFrame({'offset': range(-horizon * 60, 5, 5)})\r\n",
    "    # for each patient, same step\r\n",
    "    for p_id in all_id:\r\n",
    "        # load data\r\n",
    "        patient_data = pd.read_csv(\r\n",
    "            data_dir + \"processed_data/1_{}_h_pass_nan_check/{}.csv\".format(horizon, p_id),\r\n",
    "            index_col=False\r\n",
    "        )\r\n",
    "        # merge with time stamps\r\n",
    "        patient_data = pd.merge(\r\n",
    "            patient_data, time_stamp, how=\"outer\", on=['offset']\r\n",
    "        ).drop_duplicates()\r\n",
    "        # sort according to offset\r\n",
    "        patient_data = patient_data.sort_values(by=\"offset\", axis=0)\r\n",
    "        # forward backward fill\r\n",
    "        patient_data = patient_data.fillna(method=\"ffill\")\r\n",
    "        patient_data = patient_data.fillna(method=\"bfill\")\r\n",
    "        # take what's needed\r\n",
    "        patient_data = patient_data.loc[patient_data['offset'].isin(time_stamp['offset'].values)]\r\n",
    "        # fill na with 0\r\n",
    "        patient_data = patient_data.fillna(value=0)\r\n",
    "        # out\r\n",
    "        patient_data.to_csv('processed_data/2_{}_h/{}.csv'.format(horizon, p_id), index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}